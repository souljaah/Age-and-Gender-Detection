import tkinter as tk
from tkinter import messagebox
import cv2 as cv
from PIL import Image, ImageTk
import time

# Load pre-trained model files
faceProto = "modelNweight/opencv_face_detector.pbtxt"
faceModel = "modelNweight/opencv_face_detector_uint8.pb"
ageProto = "modelNweight/age_deploy.prototxt"
ageModel = "modelNweight/age_net.caffemodel"
genderProto = "modelNweight/gender_deploy.prototxt"
genderModel = "modelNweight/gender_net.caffemodel"

# Mean values and labels
MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)
ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']
genderList = ['Male', 'Female']

# Load networks
faceNet = cv.dnn.readNet(faceModel, faceProto)
ageNet = cv.dnn.readNet(ageModel, ageProto)
genderNet = cv.dnn.readNet(genderModel, genderProto)


# Function to get face bounding boxes
def getFaceBox(net, frame, conf_threshold=0.7):
    frameHeight, frameWidth = frame.shape[:2]
    blob = cv.dnn.blobFromImage(frame, 1.0, (300, 300), [104, 117, 123], True, False)
    net.setInput(blob)
    detections = net.forward()
    bboxes = []
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > conf_threshold:
            x1 = int(detections[0, 0, i, 3] * frameWidth)
            y1 = int(detections[0, 0, i, 4] * frameHeight)
            x2 = int(detections[0, 0, i, 5] * frameWidth)
            y2 = int(detections[0, 0, i, 6] * frameHeight)
            bboxes.append([x1, y1, x2, y2])
            cv.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
    return frame, bboxes


# Function to perform age and gender prediction
def age_gender_detector(frame):
    frameFace, bboxes = getFaceBox(faceNet, frame)
    for bbox in bboxes:
        try:
            face = frame[max(0, bbox[1] - 20):min(bbox[3] + 20, frame.shape[0] - 1),
                   max(0, bbox[0] - 20):min(bbox[2] + 20, frame.shape[1] - 1)]
            blob = cv.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)

            # Gender prediction
            genderNet.setInput(blob)
            genderPreds = genderNet.forward()
            gender = genderList[genderPreds[0].argmax()]

            # Age prediction
            ageNet.setInput(blob)
            agePreds = ageNet.forward()
            age = ageList[agePreds[0].argmax()]

            label = f"{gender}, {age}"
            cv.putText(frameFace, label, (bbox[0], bbox[1] - 10), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 255), 2,
                       cv.LINE_AA)
        except Exception as e:
            print("Error during face processing:", e)
    return frameFace


# Tkinter App
class AgeGenderApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Age and Gender Detection")
        self.root.geometry("800x600")

        # Label for video
        self.video_label = tk.Label(self.root)
        self.video_label.pack()

        # Buttons
        self.start_button = tk.Button(self.root, text="Real-Time Age and Gender Detection", command=self.start_camera,
                                      width=30, height=2)
        self.start_button.pack(pady=10)

        self.exit_button = tk.Button(self.root, text="Exit", command=self.root.quit, width=20, height=2)
        self.exit_button.pack(pady=10)

        self.cap = None  # Initialize the VideoCapture object

    def start_camera(self):
        # Start the video capture
        self.cap = cv.VideoCapture(0)
        self.update_frame()

    def update_frame(self):
        if self.cap is not None and self.cap.isOpened():
            ret, frame = self.cap.read()
            if ret:
                # Only process every 5th frame to reduce lag
                if int(time.time() * 1000) % 5 == 0:
                    processed_frame = age_gender_detector(frame)
                else:
                    processed_frame = frame

                processed_frame = cv.cvtColor(processed_frame, cv.COLOR_BGR2RGB)
                img = Image.fromarray(processed_frame)
                imgtk = ImageTk.PhotoImage(image=img)
                self.video_label.imgtk = imgtk
                self.video_label.configure(image=imgtk)

        self.root.after(10, self.update_frame)

    def __del__(self):
        if self.cap is not None and self.cap.isOpened():
            self.cap.release()


# Run the application
root = tk.Tk()
app = AgeGenderApp(root)
root.mainloop()

